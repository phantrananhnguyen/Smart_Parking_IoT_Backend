import os
import cv2
import traceback
import re
import numpy as np
from PIL import Image
from datetime import datetime
from flask import Flask, request, jsonify
from ultralytics import YOLO
from vietocr.tool.predictor import Predictor
from vietocr.tool.config import Cfg

# ============================
# 1Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh YOLOv8 v√† VietOCR
# ============================
print("üîÅ ƒêang t·∫£i m√¥ h√¨nh YOLOv8 v√† VietOCR...")
model = YOLO('E:\\Downloads\\bienso\\bienso\\runs\\detect\\train3\\weights\\best.pt')

config = Cfg.load_config_from_name('vgg_transformer')
config['weights'] = 'E:\\Downloads\\bienso\\bienso\\vgg-transformer.pth'
config['cnn']['pretrained'] = False
config['device'] = 'cuda'
ocr = Predictor(config)
print("‚úÖ M√¥ h√¨nh ƒë√£ s·∫µn s√†ng.")

# ============================
# 2Ô∏è‚É£ Th∆∞ m·ª•c l∆∞u ·∫£nh debug
# ============================
os.makedirs('plates', exist_ok=True)
pattern = re.compile(r'^\d{2}[A-Z]{1,2}\d{3,5}$', re.IGNORECASE)

def clean_text(text):
    # X√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ l·∫°i ch·ªØ v√† s·ªë
    return re.sub(r'[^A-Z0-9]', '', text.upper())

def recognize_from_image_array(frame):
    results = model(frame)
    plates_text = []

    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = map(int, box.cpu().numpy())
        plate_img = frame[y1:y2, x1:x2]

        # (Optional) l∆∞u ·∫£nh bi·ªÉn s·ªë ƒë·ªÉ debug
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')

        try:
            pil_img = Image.fromarray(plate_img).convert('RGB')
            plate_np = np.array(pil_img)
            h, w = plate_np.shape[:2]

            if h > 0.5 * w:
                upper = plate_np[0:h//2, :]
                lower = plate_np[h//2:, :]
                up_text = ocr.predict(Image.fromarray(upper)).strip()
                lo_text = ocr.predict(Image.fromarray(lower)).strip()
                text = up_text + lo_text
            else:
                text = ocr.predict(pil_img).strip()

            # Chu·∫©n h√≥a text: b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, uppercase
            text = clean_text(text)

            # Ki·ªÉm tra pattern h·ª£p l·ªá
            if text and pattern.match(text):
                plates_text.append(text)
            else:
                print(f"[‚ö†Ô∏è Kh√¥ng h·ª£p l·ªá]: {text}")

        except Exception as e:
            print("[‚ùå OCR l·ªói]:", e)
            traceback.print_exc()

    return plates_text

# ============================
# 4Ô∏è‚É£ Flask API
# ============================
app = Flask(__name__)

@app.route('/recognize', methods=['POST'])
def recognize():
    if 'image' not in request.files:
        return jsonify({'error': 'Missing image'}), 400
    try:
        data = request.files['image'].read()
        frame = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
        results = recognize_from_image_array(frame)

        # üîî In ra console c√°c bi·ªÉn s·ªë ƒë√£ detect ƒë∆∞·ª£c
        if results:
            print(f"[API] Detected plates: {results}")
        else:
            print("[API] No plates detected.")

        return jsonify({ 'plate': results[0] if results else "",'plates': results})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=True)
